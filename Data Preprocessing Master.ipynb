{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from yellowbrick.target import ClassBalance\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and create a copy to use to verify preprocessing steps\n",
    "quicken_df = pd.read_csv('data/quicken_2019.csv')\n",
    "check_df = quicken_df.copy()\n",
    "# Pull Census Tract dictionary from different notebook\n",
    "%store -r FIPS_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Condense High Cardinality Variables\n",
    "Action Taken: \n",
    "* 1: Loan originated\n",
    "* 2: Application approved but not accepted\n",
    "* 3: Application denied\n",
    "* 4: Application withdrawn by applicant\n",
    "* 5: File closed for incompleteness\n",
    "* 6: Purchased loan\n",
    "* 7: Preapproval request denied\n",
    "* 8: Preapproval request approved but not accepted\n",
    "\n",
    "Interpreting which actions are 'approved:' \n",
    "1, 2, 6\n",
    "\n",
    "Denied:\n",
    "3\n",
    "\n",
    "Irrelevant to model: 4, 5, 7, 8\n",
    "\n",
    "-------\n",
    "* Race and Ethnicity columns both allow the applicant to report a more specific value. For example, an applicant can select Asian (2) or more specifically Chinese(22), etc. Because this column will be onehotencoded, I'm going to simplify these columns to the top-level categories:\n",
    "    - American Indian or Alaska Native\n",
    "    - Asian\n",
    "    - Black or African American\n",
    "    - Native Hawaiian or Other Pacific Islander\n",
    "    - White\n",
    "    - Hispanic\n",
    "    - Non-Hispanic\n",
    "------------\n",
    "\n",
    "Census Tract\n",
    "* The Census Tract column contains ~65K unique values, 366 of which are NA. These were mapped to 10 'primary codes' which indicate if a region is rural, urban, metropolitan, etc. However, because I couldn't use the mapper dictionary if null values were present, dropped these in this preprocessing step rather than in the general missing values section, below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action taken\n",
    "quicken_df = quicken_df[~quicken_df['action_taken'].isin([4,5,7,8])]\n",
    "quicken_df['action_taken'] = quicken_df['action_taken'].map(lambda x: 0 if x ==3 else 1)\n",
    "\n",
    "# applicant race \n",
    "def condense_race(x): \n",
    "    if x == 6 or x == 7:\n",
    "        x = np.nan\n",
    "    if x> 10 and x < 20: \n",
    "        x = 1\n",
    "    if x> 20 and x < 30: \n",
    "        x = 2\n",
    "    if x> 40 and x < 50: \n",
    "        x = 4\n",
    "    else: \n",
    "        x = x\n",
    "    return x\n",
    "\n",
    "# applicant ethnicity\n",
    "def condense_ethnicity(x): \n",
    "    if x == 3 or x == 4: \n",
    "        x = np.nan\n",
    "    if x !=2: \n",
    "        x = 1\n",
    "    else: \n",
    "        x = x\n",
    "    return x \n",
    "\n",
    "def condense_sex(x): \n",
    "    if x == 3 or x == 4: \n",
    "        x = np.nan\n",
    "    else: \n",
    "        x = x\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "quicken_df['applicant_race-1'] = quicken_df['applicant_race-1'].apply(lambda x: condense_race(x))\n",
    "quicken_df['applicant_ethnicity-1'] = quicken_df['applicant_ethnicity-1'].apply(lambda x: condense_ethnicity(x))\n",
    "quicken_df['applicant_sex'] = quicken_df['applicant_sex'].apply(lambda x: condense_sex(x))\n",
    "\n",
    "quicken_df = quicken_df.dropna(subset=['census_tract'])\n",
    "quicken_df['census_tract'] = quicken_df['census_tract'].astype(int)\n",
    "quicken_df['census_tract'] = quicken_df['census_tract'].astype(str)\n",
    "quicken_df['census_tract'] = quicken_df['census_tract'].map(FIPS_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "* Planned to add the following columns: \n",
    "    - has co-signer\n",
    "    - bi/multi-racial\n",
    "    - co-signer bi/multi-racial\n",
    "    \n",
    "However, FFEIC updated their datasets with new \"derived\" variables, which already achieve this goal for race, ethnicity, and sex. These values don't add up to the original field. Will use both for now. \n",
    "\n",
    "* Ordinal Encoding for Age column\n",
    "* DIR contains str and int, mapped using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ordinalencoder object\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "# Convert column to array\n",
    "age_df = quicken_df[['applicant_age']].to_numpy()\n",
    "enc.fit(age_df)\n",
    "enc.categories_\n",
    "\n",
    "# fitted encoder to array\n",
    "enc_age_arr = enc.transform(quicken_df[['applicant_age']].to_numpy())\n",
    "\n",
    "# Apply encoder transformation\n",
    "quicken_df['applicant_age'] = enc_age_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_mapper = {'20%-<30%': 25, '30%-<36%': 33, '>60%': 65, '<20%': 15, '50%-60%': 55}\n",
    "\n",
    "\n",
    "quicken_df['debt_to_income_ratio'] = quicken_df['debt_to_income_ratio'] \\\n",
    "                                    .map(lambda x: DIR_mapper[x] if x in DIR_mapper else int(x), na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Missing Values\n",
    "1. Some variables are perfect predictors when they are null. Filled all nan values with 99 so I could run a crosstabulation to check for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "quicken_df['income'] = quicken_df['income'].fillna(quicken_df['income'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "quicken_df = quicken_df.fillna(99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Selection\n",
    "1. Drop columns containing only one unique value\n",
    "Null values are represented differently for each variable in the dataset. Looked at each variable and recoded null values to 99 where applicable\n",
    "2. Check for perfect predictors and drop those\n",
    "3. Drop certain columns based on what information is relevant. This will apply to all lenders\n",
    "    a. ```state_code``` and ```county_code``` - using census tract and ```derived_msa-md``` because they are more informative\n",
    "4. ```Income``` converted na back to np.nan and will impute median for this column\n",
    "5. There are several census features that were appended to the dataset after the lender submitted their report. While these features might be used in a different part of this study, they will be excluded from the dataset that will be fed into the model, as the bank did not report these values. \n",
    "6. Exclude 2nd lien mortgage, interest only payment loans (only ~400 of these loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_predictors = []\n",
    "for col in quicken_df.columns: \n",
    "    cross = pd.crosstab(quicken_df[col], quicken_df['action_taken'])\n",
    "    if cross[0].sum() == 0 or cross[1].sum() == 0:\n",
    "        perfect_predictors.append(col)\n",
    "perfect_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unique_value_lst = []\n",
    "for col in quicken_df.columns:\n",
    "    if len(quicken_df[col].unique()) ==1: \n",
    "        one_unique_value_lst.append(col)\n",
    "quicken_df = quicken_df.drop(one_unique_value_lst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null coded as 99999, 0, 5 --> recode to 99\n",
    "quicken_df['derived_msa-md'] = quicken_df['derived_msa-md'].apply(lambda x: 99 if x == 99999 else x)\n",
    "quicken_df['purchaser_type'] = quicken_df['purchaser_type'].apply(lambda x: 99 if x == 0 else x)\n",
    "quicken_df['loan_purpose'] = quicken_df['loan_purpose'].apply(lambda x: 99 if x == 5 else x)\n",
    "quicken_df['applicant_credit_score_type'] = quicken_df['applicant_credit_score_type'] \\\n",
    "                                                    .apply(lambda x: 99 if x == 9 else x)\n",
    "quicken_df['applicant_ethnicity_observed'] = quicken_df['applicant_ethnicity_observed'] \\\n",
    "                                                    .apply(lambda x: 99 if x == 3 else x)\n",
    "quicken_df['applicant_race_observed'] = quicken_df['applicant_race_observed'] \\\n",
    "                                                    .apply(lambda x: 99 if x == 3 else x)\n",
    "quicken_df['submission_of_application'] = quicken_df['submission_of_application'] \\\n",
    "                                                    .apply(lambda x: 99 if x == 3 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop b/c irrelevant or class imbalance is extreme \n",
    "drop_irrelevant = ['state_code', 'county_code', 'open-end_line_of_credit', 'manufactured_home_land_property_interest', \n",
    "                  'manufactured_home_secured_property_type', 'co-applicant_credit_score_type', 'applicant_ethnicity-2',\n",
    "                  'applicant_ethnicity-3', 'applicant_ethnicity-4', 'co-applicant_ethnicity-1', 'co-applicant_ethnicity-2',\n",
    "                  'co-applicant_ethnicity-3', 'co-applicant_ethnicity-4', 'co-applicant_ethnicity_observed',\n",
    "                  'applicant_race-2', 'applicant_race-3', 'applicant_race-4', 'applicant_race-5', \n",
    "                  'co-applicant_race-1', 'co-applicant_race-2', 'co-applicant_race-3', 'co-applicant_race-4', \n",
    "                  'co-applicant_race-5', 'co-applicant_race_observed', 'co-applicant_sex', 'applicant_sex_observed',\n",
    "                  'co-applicant_sex_observed', 'co-applicant_age', 'applicant_age_above_62', 'co-applicant_age_above_62',\n",
    "                  'submission_of_application', 'derived_loan_product_type', 'interest_only_payment']\n",
    "\n",
    "confirmed_perfect_pred = ['denial_reason-1', 'denial_reason-2', 'denial_reason-3', 'purchaser_type', 'preapproval', \n",
    "                       'interest_rate', 'rate_spread', 'hoepa_status', 'total_loan_costs', 'origination_charges', \n",
    "                       'discount_points', 'lender_credits', 'initially_payable_to_institution']\n",
    "\n",
    "census_appended = ['tract_minority_population_percent', 'tract_population', 'ffiec_msa_md_median_family_income',\n",
    "                  'tract_to_msa_income_percentage', 'tract_owner_occupied_units', 'tract_one_to_four_family_homes',\n",
    "                  'tract_median_age_of_housing_units']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "quicken_df = quicken_df.drop(drop_irrelevant + confirmed_perf_pred + census_appended, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselections of relevant variables\n",
    "quicken_df = quicken_df[quicken_df['lien_status'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Class Imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boa_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4ce43c64d2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboa_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action_taken'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'boa_df' is not defined"
     ]
    }
   ],
   "source": [
    "boa_df['action_taken'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examing Colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Perfect Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
